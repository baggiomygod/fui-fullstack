# 日志
## 1. 访问日志
## 2. 自定义日志

## 3. node.js 文件操作, node.js stream

## 4. 日志开发

## 5. 日志拆分

### 日志为什么不存在redis mysql
reids:
1. 日志文件会很大，不适合存在redis中
2. 性能要求不高，
mysql:
3. mysql需要是有表结构

>  IO操作的性能瓶颈
> - IO ： 网络IO 文件IO
> - 相比cpu计算机和内存读写，IO的突出特点就是：慢！
> - 如何在有限的硬件资源下提供IO的操作效率

### stream
```
// 标准输入输出，pipe就是管道（符合水流管道的模型图）
// process.stdin 获取数据，直接通过管道传递geiprocess。stdout
process.stdin.pipe(process.stdout)
```

```
    const http = require('http')
    const server = http.createServer((req, res) => {
        if (req.method === 'POST') {
            req.pipe(res)
        }
    })
    server.listen(5000)
```

#### 1. stream操作文件
```
    const fs = require('fs')
    const path = require('path')

    // 要读取文件的路径
    const filename1 = path.resolve(__dirname, 'data.txt')
    const filrname2 = path.resolve(__dirname, 'data-bak.txt')

    // 读取文件的stream对象
    const readStream = fs.createReadStream(fileName1)
    const writeStream = fs.createWriteStream(fileName2)

    // 执行拷贝，通过pipe， file1 --pipe--> file2
    readStream.pipe(writeStream)

    readStream.on('end', function () {
        console.log('拷贝完成')
    })
```

```
    const http = require('http')
    const fs = require('fs')
    const path = require('path')

    const server = http.createServer((req, res) => {
        const method = req.method
        if (method === 'GET') {
            const fileName = path.resolve(__dirname, 'data.txt')
            const stream = fs.createReadStream(fileName)
            stream,pipe(res)
        }
    })

    server.listen(8085)
```

### 2. 日志拆分
- 按时间划分日志：201-01-01.access.log
- 实现当时：linux的crontab命令，定时任务

编写sh文件
```
#!/bin/sh

cd /Users/wengf/work/self_test/1.test/7.mooc-pay/fui_admin_fullstack/blog_server_node/blog-node/logs
cp access.log $(data +%Y-%m-%d-%H).access.log
echo "" > access.log
```
运行```sh copy.sh```

#### crontab
- 设置定时任务： ***** command
每天零点执行copy.sh
```
    crontab -e
    # *分钟 *小时 *年 *月 *星期
    * 0 * * * sh /Users/wengf/work/self_test/1.test/7.mooc-pay/fui_admin_fullstack/blog_server_node/blog-node/src/utils/copy.sh
```

- 将access.log拷贝并重命名为2019-02-02.access.log
- 清空access.log 文件，继续基类日志


### 日志分析
- 针对access.log 分析chrome占比
- 日志是按行存储的，一行就是一条日志
- 使用node.js的readline（基于stream 效率高）

node readline
```
    // util/readline.js
```

## 总结
通过stream提高IO性能
crontab拆分日志